{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f0e123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel.kernel import Kernel\n",
    "from semantic_kernel.functions.kernel_function import KernelFunction\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.azure_chat_prompt_execution_settings import AzureChatPromptExecutionSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5877289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.prompt_template import InputVariable, PromptTemplateConfig\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb4051e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create the kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Add Azure OpenAI chat completion service\n",
    "chat_completion = AzureChatCompletion(\n",
    "    deployment_name=\"gpt-4o-mini\",  # Replace with your actual deployment name\n",
    "    endpoint=\"https://exquitech-openai-2.openai.azure.com/\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    ")\n",
    "kernel.add_service(chat_completion, \"chat_completion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6cc077fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt\n",
    "prompt = \"Give a fun fact about: {{$input}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4cfd3",
   "metadata": {},
   "source": [
    "This is your prompt template string.\n",
    "\n",
    "{{$input}} is a placeholder that will be replaced dynamically with the user input (like \"bananas\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b504ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution settings for Azure\n",
    "execution_settings = AzureChatPromptExecutionSettings(\n",
    "    service_id=\"default\",  # match what you set when adding the service\n",
    "    ai_model_id=\"gpt-4o-mini\",  # or whatever your Azure deployment name is\n",
    "    temperature=0.7,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0520d95b",
   "metadata": {},
   "source": [
    "This configures how the prompt will be sent to Azure:\n",
    "\n",
    "- temperature=0.7: Controls randomness in generation (higher = more creative).\n",
    "\n",
    "- ai_model_id: The Azure model to use.\n",
    "\n",
    "- service_id: Connects to the previously added service named \"default\" or \"chat_completion\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddac2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template config\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    name=\"GetFunFact\",\n",
    "    template=prompt,\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"Topic to get a fun fact about\", is_required=True)\n",
    "    ],\n",
    "    execution_settings=execution_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c9b706",
   "metadata": {},
   "source": [
    "This creates a structured prompt template object.\n",
    "\n",
    "InputVariable defines what input the prompt expects (input variable with description).\n",
    "\n",
    "This formalizes how inputs will be injected into the prompt string.\n",
    "\n",
    "execution_settings ties the prompt to how it will be executed by the AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a38b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_fact_function = kernel.add_function(\n",
    "    prompt=prompt,\n",
    "    plugin_name=\"FunFacts\",                         # Logical grouping of related functions\n",
    "    function_name=\"GetFunFact\",                     # Function identifier inside the plugin\n",
    "    prompt_execution_settings=execution_settings,   # Execution settings for this function\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ecad1a",
   "metadata": {},
   "source": [
    "This creates a KernelFunction from your prompt string:\n",
    "\n",
    "- This function knows how to:\n",
    "\n",
    "    - Take input,\n",
    "\n",
    "    - Inject it into the prompt,\n",
    "\n",
    "    - Send the prompt to the AI service,\n",
    "\n",
    "    - Return the AI response.\n",
    "\n",
    "plugin_name lets you group similar functions together (like \"FunFacts\").\n",
    "\n",
    "function_name names this specific function for invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21f0e4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fun fact about bananas is that they are technically classified as berries! In botanical terms, a berry is a fruit produced from the ovary of a single flower with seeds embedded in the flesh. So, while we often think of strawberries and raspberries as berries, bananas fit the true definition of a berry!\n"
     ]
    }
   ],
   "source": [
    "result = await kernel.invoke(plugin_name=\"FunFacts\", function_name=\"GetFunFact\", input=\"bananas\")\n",
    "print(str(result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fb8d8",
   "metadata": {},
   "source": [
    "You call the function, passing \"bananas\" as the input.\n",
    "\n",
    "Kernel will:\n",
    "\n",
    "- Inject \"bananas\" into the prompt: \"Give a fun fact about: bananas\".\n",
    "\n",
    "- Send prompt to Azure OpenAI.\n",
    "\n",
    "- Wait for the AI's response.\n",
    "\n",
    "- Return the response as result.\n",
    "\n",
    "You print the fun fact response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c36476",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
